{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatsDogs_TF.ipynb\n",
    "\n",
    "+ The code in this notebook dmonstrates image classification using convolutional network models under Python/TF/Keras and the effect of max pooling and image augmentation.\n",
    "\n",
    "+ The API is TF/Kever 2.18\n",
    "\n",
    "+ The data consists of the cats/dogs image data from Kaggle. The data is located  in two directories, FullSet and SmallSet.\n",
    "\n",
    "```\n",
    "    /drv3/hm3/Data/ImgData/CatsDogs_Kaggle/SmallSet/\n",
    "    /drv3/hm3/Data/ImgData/CatsDogs_Kaggle/FullSet/\n",
    "```\n",
    "Both datasets have the following structure.\n",
    "\n",
    "    .../SmallSet/train/{cat, dog}      # 1,000 images of cats and 1,000 of dogs\n",
    "    ...SmallSet/test/{cat, dog}        # 1,000 images of cats and 1,000 of dogs\n",
    "    .../SmallSet/validation{cat,dog}   # 500 images of cats and 500 of dogs\n",
    "\n",
    "    .../FullSet/train/{cat, dog}       # 5,000 images of cats and 5,000 of dogs\n",
    "    .../FullSet/test/{cat, dog}        # 5,000 images of cats and 5,000 of dogs\n",
    "    .../FullSet/validation{cat, dog}   # 2490 images of cats and 2469 dogs\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt  # For visualization (optional)\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ic is the \"right printer for debugging\"\n",
    "ic (\"TF Version   \", tf.__version__)\n",
    "ic (\"TF Path      \", tf.__path__[0])\n",
    "ic (\"Keras version \", keras.__version__)\n",
    "ic (\"numpy version \", np.__version__)\n",
    "ic(\"This is ic\")\n",
    "ic(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dataset Path and Parameters\n",
    "data_dir = \"/drv3/hm3/Data/ImgData/CatsDogs_Kaggle/FullSet/\"\n",
    "\n",
    "data_dir = \"/drv3/hm3/Data/ImgData/CatsDogs_Kaggle/SmallSet/\"\n",
    "\n",
    "image_height = 150  # Adjust as needed\n",
    "image_width = 150  # Adjust as needed\n",
    "batch_size = 32      # Adjust as needed\n",
    "epochs = 20         # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Get Class Names by Inspecting Directory (Essential)\n",
    "class_names = sorted(os.listdir(data_dir))  # Get sorted list of subdirectories\n",
    "num_classes = len(class_names) # Get number of classes\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Loading and Preprocessing using image_dataset_from_directory\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir + \"/train\",  # Path to training data\n",
    "    labels='inferred',     # Infer labels from directory structure\n",
    "    label_mode='binary',   # Use binary labels (0 for cat, 1 for dog)\n",
    "    image_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,          # Shuffle the training data\n",
    "    validation_split=0.2,  # Create a validation set (optional)\n",
    "    subset=\"training\",      # Specify this is the training set\n",
    "    seed=123               # For reproducibility (optional)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir + \"/train\",  # Same directory as training, but different subset\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,         # No need to shuffle validation data\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.  Mapping Labels (if needed for display or other purposes)\n",
    "# This is how we can map back to class names:\n",
    "label_map = dict(zip(range(num_classes), class_names))\n",
    "\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(len(images)):\n",
    "        label_index = int(labels[i].numpy())\n",
    "        class_name = label_map[label_index] # Get the class name\n",
    "        # print(f\"Image {i+1}: {class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir + \"/test\",  # Path to test data\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False        # No need to shuffle test data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Data Augmentation (Optional but Highly Recommended)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "  tf.keras.layers.RandomRotation(0.1),\n",
    "  # Add more augmentation layers as needed (e.g., zoom, shear)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of applying augmentation:\n",
    "for images, labels in train_dataset.take(1):  # Take one batch\n",
    "    augmented_images = data_augmentation(images)\n",
    "    # ... use augmented_images in training loop ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Prefetching (Essential for Performance)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Display a few good images \n",
    "\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):  # Display 9 images\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[int(labels[i])]) # Convert to int for indexing\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255, input_shape=(image_height, image_width, 3)), # Normalize pixel values\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer (1 neuron for binary)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Model Compilation\n",
    "model.compile(\n",
    "    optimizer='adam',  # We can experiment with other optimizers\n",
    "    loss='binary_crossentropy', # Let's use 'categorical_crossentropy' for > 2 classes\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Model Training\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Evaluate Model \n",
    "# test_dataset = ...  # Load the test dataset\n",
    "\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# 6. Plot Training History (Optional but very useful)\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7. Save the model\n",
    "# File is quite big (228 MB) \n",
    "model.save(\"/drv3/hm3/Data/ImgData/CatsDogs_Kaggle/SmallSet/NewSavedModel/newmodel.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
