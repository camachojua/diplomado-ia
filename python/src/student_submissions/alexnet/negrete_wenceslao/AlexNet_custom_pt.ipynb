{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fccb904f-d62e-4b25-977f-82dd66fb64e9",
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02bd6d01-ebab-4bc9-a046-074e27bdc70d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7eaf60a-ffc1-4477-82be-52a270419856",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the AlexNet architecture from scratch\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        # Original AlexNet was designed for 224x224 images\n",
        "        # We'll adapt it for CIFAR-10's 32x32 images by using smaller filters and strides\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.features = nn.Sequential(\n",
        "            # Conv1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv2\n",
        "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv3\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv4\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Conv5\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 28 * 28, 4096),  # Correct dimensions for 224x224 input\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5501f661-126d-457f-9c79-86753e5afc9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data loading and preprocessing\n",
        "def load_cifar10():\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Resize(224),  # AlexNet expects 224x224 images\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize(224),  # Also resize test images to match\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "    return trainloader, testloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d40b4f3-37f8-4c5a-8d82-276817afdbfa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train_model(model, trainloader, epochs=10, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(trainloader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accs.append(epoch_acc)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%, Time: {epoch_time:.2f}s')\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return train_losses, train_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c1eebb2-3e51-4e95-90e5-e0602c0115bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "def evaluate_model(model, testloader, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a886d5a-667d-4260-b0ce-f3697ff884b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set epochs and device\n",
        "epochs=5\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b1ad5c-23c6-4313-8d43-1d9cae492a10",
      "metadata": {},
      "outputs": [],
      "source": [
        "trainloader, testloader = load_cifar10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19f47b0-8259-49c5-a1ae-e9a80027afd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nTraining custom AlexNet...\")\n",
        "custom_alexnet = AlexNet(num_classes=10)\n",
        "custom_losses, custom_accs = train_model(custom_alexnet, trainloader, epochs=epochs, device=device)\n",
        "custom_test_acc = evaluate_model(custom_alexnet, testloader, device=device)\n",
        "print(f\"Custom AlexNet Test Accuracy: {custom_test_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e70be062-f0d6-4ad2-961a-5a87e032af6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, epochs+1), custom_losses, 'r-', label='Pretrained')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, epochs+1), custom_accs, 'r-', label='Pretrained')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
