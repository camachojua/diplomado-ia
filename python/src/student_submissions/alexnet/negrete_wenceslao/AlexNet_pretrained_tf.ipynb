{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Define the AlexNet architecture\n",
        "def create_alexnet(num_classes=10):\n",
        "    model = models.Sequential([\n",
        "        # Conv1\n",
        "        layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=(227, 227, 3)),\n",
        "        layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "        \n",
        "        # Conv2\n",
        "        layers.Conv2D(192, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "        \n",
        "        # Conv3\n",
        "        layers.Conv2D(384, kernel_size=3, padding='same', activation='relu'),\n",
        "        \n",
        "        # Conv4\n",
        "        layers.Conv2D(256, kernel_size=3, padding='same', activation='relu'),\n",
        "        \n",
        "        # Conv5\n",
        "        layers.Conv2D(256, kernel_size=3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "        \n",
        "        # Fully connected layers\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "        layers.Dense(num_classes)\n",
        "    ])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Data loading and preprocessing\n",
        "def load_cifar10():\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "    \n",
        "    # Convert to float32 and normalize\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    x_test = x_test.astype('float32') / 255\n",
        "    \n",
        "    # Resize images to 227x227 (AlexNet's original input size)\n",
        "    x_train_resized = tf.image.resize(x_train, (227, 227))\n",
        "    x_test_resized = tf.image.resize(x_test, (227, 227))\n",
        "    \n",
        "    # Apply ImageNet normalization\n",
        "    x_train_normalized = imagenet_utils.preprocess_input(x_train_resized)\n",
        "    x_test_normalized = imagenet_utils.preprocess_input(x_test_resized)\n",
        "    \n",
        "    # Convert labels to categorical\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "    \n",
        "    return (x_train_normalized, y_train), (x_test_normalized, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Custom callback for timing epochs\n",
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "        \n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Set up GPU if available\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "device = \"/GPU:0\" if len(tf.config.list_physical_devices('GPU')) > 0 else \"/CPU:0\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = load_cifar10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Create and compile model\n",
        "with tf.device(device):\n",
        "    model = create_alexnet()\n",
        "    \n",
        "    # Compile model with SGD optimizer and cosine decay\n",
        "    initial_learning_rate = 0.01\n",
        "    epochs = 5\n",
        "    decay_steps = epochs * len(x_train) // 64  # assuming batch_size=64\n",
        "    \n",
        "    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
        "        initial_learning_rate, decay_steps)\n",
        "    \n",
        "    optimizer = optimizers.SGD(learning_rate=lr_schedule, \n",
        "                             momentum=0.9)\n",
        "    \n",
        "    model.compile(optimizer=optimizer,\n",
        "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    # Train model\n",
        "    time_callback = TimeHistory()\n",
        "    history = model.fit(x_train, y_train,\n",
        "                       batch_size=64,\n",
        "                       epochs=epochs,\n",
        "                       validation_data=(x_test, y_test),\n",
        "                       callbacks=[time_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Evaluate model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"\\nTest accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Plot training curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, epochs+1), history.history['loss'], 'r-', label='Training')\n",
        "plt.plot(range(1, epochs+1), history.history['val_loss'], 'b-', label='Validation')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, epochs+1), history.history['accuracy'], 'r-', label='Training')\n",
        "plt.plot(range(1, epochs+1), history.history['val_accuracy'], 'b-', label='Validation')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print average epoch time\n",
        "avg_epoch_time = np.mean(time_callback.times)\n",
        "print(f\"\\nAverage epoch time: {avg_epoch_time:.2f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
