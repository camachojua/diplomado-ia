import Pkg
Pkg.add(["CSV", "DataFrames", "Tables"])

# Aqui solo estamos evitando volver a cargar la paqueteria tras cada ejecucion
import Pkg; Pkg.offline(true)

#= Este programa resuelve el problema de movielense en Julia
lo que hace es cargar en streaming el archivo rating.csv y unir
los chunks contra el archivo movies.csv, despues cuenta el 
numero de ratings para cada genero y suma las calificaciones 
de cada pelicula por genero en un diccionario
=#

using CSV, DataFrames, Dates, Base.Threads, Printf

# Definimos los géneros que se van a buscar
GENEROS = [
    "Action", "Adventure", "Animation", "Children", "Comedy", "Crime", "Documentary",
    "Drama", "Fantasy", "Film-Noir", "Horror", "IMAX", "Musical", "Mystery", "Romance",
    "Sci-Fi", "Thriller", "War", "Western", "(no genres listed)"
]

# Función para contar ocurrencias por género y sumar ratings por género
function count_genres(df::DataFrame, genres::Vector{String})::Dict{String, Tuple{Int, Float64}}
    #= Definimos un diccionario genre_counts donde sus entradas van a ser 
    genero: (cuenta, suma ratings) =#
    genre_counts = Dict(g => (0, 0.0) for g in genres)

    # Accedemos a toda la columna :genres del DataFrame unido
    for (i, genre_list) in enumerate(df[!, :genres])
        # Obtener el rating específico de la fila actual
        rating = df[i, :rating]  
        for genre in split(genre_list, "|")
            #= Se busca el género en el diccionario para cada género por fila
            y se suma la incidencia y el rating sobre el diccionario =#
            if haskey(genre_counts, genre)
                count, sum_ratings = genre_counts[genre]
                genre_counts[genre] = (count + 1, sum_ratings + rating)
            end
        end
    end
    return genre_counts
end

# Función para hacer join sobre los chunks de ratings y movies_df
function process_chunk(ratings_chunk::DataFrame, movies_df::DataFrame, chunk_id::Int)
    println("Procesando fragmento $chunk_id...")  # Debug: imprime el ID del fragmento que se está procesando

    #= Solo tomamos las columnas necesarias de ratings_chunk, en el caso de movies_df
    el DataFrame ya tiene solamente las columnas que necesitamos =#
    joined_df = innerjoin(movies_df, ratings_chunk[:, ["movieId", "rating"]], on="movieId")

    # Más debug :,v
    #println("Fragmento $chunk_id procesado con éxito, filas unidas: ", nrow(joined_df))
    return count_genres(joined_df, GENEROS)
end

# Función para contar el número de líneas en el archivo
function count_lines(file_path::String)::Int
    line_count = 0
    # Abrimos el archivo en modo solo lectura y recorremos cada línea aumentando un contador += 1
    open(file_path, "r") do file
        for _ in eachline(file)
            line_count += 1
        end
    end
    return line_count
end

# Función principal que implementa procesamiento distribuido con hilos
function main_process_distributed(ratings_path::String, movies_path::String, chunk_size::Int)
    # Leer datos completos de las películas
    movies_df = CSV.File(movies_path, select=["movieId", "genres"]) |> DataFrame

    # Omitimos la primera línea para no tener problemas con el encabezado
    total_lines = count_lines(ratings_path) - 1  
    row_start = 2  

    #= Generamos un diccionario igual al de arriba donde vamos a almacenar 
    el resultado de todos los hilos =#
    overall_genre_counts = Dict(g => (0, 0.0) for g in GENEROS)

    # Lista para almacenar las tareas (hilos)
    tasks = []

    # Iteramos con un while mientras queden líneas por analizar
    while row_start <= total_lines
        #= Generamos el ratings_chunk DataFrame, donde avanzamos desde el final del chunk anterior
        hasta (final_chunk_anterior + líneas a analizar), donde líneas a analizar es una constante
        suministrada por el usuario =#
        ratings_chunk = CSV.File(ratings_path; header=true, limit=chunk_size, skipto=row_start) |> DataFrame

        #= Creamos una tarea para procesar el fragmento en paralelo
        y la agregamos a la lista de tareas =#
        task = Threads.@spawn process_chunk(ratings_chunk, movies_df, row_start)
        push!(tasks, task)  # Agregar la tarea a la lista

        # Movemos el inicio de la siguiente carga
        row_start += chunk_size  
    end

    # Esperamos a que todas las tareas terminen y sumamos los resultados
    for task in tasks
        genre_counts = fetch(task)  # Obtener el resultado de la tarea
        for (genre, (count, sum_ratings)) in genre_counts
            overall_count, overall_sum_ratings = overall_genre_counts[genre]
            overall_genre_counts[genre] = (overall_count + count, overall_sum_ratings + sum_ratings)
        end
    end

    return overall_genre_counts
end

# Medimos el tiempo de ejecución
time_start = Dates.now()
result = main_process_distributed("ratings.csv", "movies.csv", 5000000)  # Ajusta chunk_size según la memoria disponible
println("Conteo total: \n")

# Imprimimos los resultados alineados
for (genre, (count, sum_ratings)) in result
    @printf("%-20s | %-10d | %-10.3f\n", genre, count, sum_ratings / count)
end
