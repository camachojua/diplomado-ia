{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d71e120-ab0b-46e9-862b-2906253b288f",
   "metadata": {},
   "source": [
    "# Ejercicio 3: Clasificación\n",
    "_Felipe Andres Castillo_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b852c9-d0e1-43b8-b9b8-fda7a514a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "#Pkg.update()\n",
    "#Pkg.precompile()\n",
    "#Pkg.activate(\"my_MLJ_env\", shared=true)\n",
    "#Pkg.add(\"MLJ\")\n",
    "#Pkg.add(\"RDatasets\")\n",
    "#Pkg.add(\"GLM\")\n",
    "#Pkg.add(\"GLMNet\")\n",
    "#Pkg.add(url = \"https://github.com/diegozea/ROC.jl\")\n",
    "#Pkg.add(\"Plots\")\n",
    "#Pkg.add(\"DecisionTree\")\n",
    "#Pkg.add(\"NearestNeighbors\")\n",
    "#Pkg.add(\"LIBSVM\")\n",
    "\n",
    "using RDatasets\n",
    "using DataFrames\n",
    "using MLJ #tuve problemas al ejecutar using MLJ, por lo que eliminé la carpeta .julia/compiled y después ejecuté Pkg.precompile()\n",
    "#using CairoMakie\n",
    "using GLMNet \n",
    "using Random\n",
    "using ROC\n",
    "using DecisionTree\n",
    "using Plots\n",
    "using NearestNeighbors\n",
    "using LIBSVM\n",
    "\n",
    "include(\"./../src/exercise1_code.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d63bb7-2163-4226-a765-60ac1761974a",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a2bb5-f56d-4e3b-911f-99ef19a5a627",
   "metadata": {},
   "source": [
    "Un **índice bursátil** es un indicador de la bolsa de valores que actúa como un termómetro: tiene la capacidad de hacernos ver, en un solo vistazo, el movimiento mayoritario de las empresas de dicho mercado. **Miden el crecimiento o el decrecimiento del valor de las acciones** que lo componen, para dar una imagen del comportamiento del mercado al completo. Existen múltiples índices en todo el mundo y son de gran importancia para poder analizar cómo varía el precio de una serie de activos cotizados con unas características determinadas. \n",
    "\n",
    "Son muy utilizados por los gestores para llevar a cabo comparativas entre todos ellos y poder operar e invertir en función de los datos objeto de análisis. Además de como guía para dar una perspectiva del mercado, estos indicadores económicos se pueden utilizar para hacer un análisis y estudiar opciones a la hora de medir la rentabilidad y el riesgo del mercado, así como el rendimiento de un gestor de activos, o crear carteras que puedan reproducir el comportamiento de dicho índice, entre otros. \n",
    "\n",
    "En este reporte, se utilizan datos del índice bursátil Standard & Poor's para aplicar diversos algoritmos de clasificación con el objetivo de predecir si el mercado estará al alza o a la baja, basándose en los rendimientos porcentuales de un día específico.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d024b30-6b6b-4f76-a998-a43fb72517ab",
   "metadata": {},
   "source": [
    "## Stock Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd979cc-9600-4012-887b-6bc168e2cb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame consta de 9 columnas y 1250 registros\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>9×7 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">variable</th><th style = \"text-align: left;\">mean</th><th style = \"text-align: left;\">min</th><th style = \"text-align: left;\">median</th><th style = \"text-align: left;\">max</th><th style = \"text-align: left;\">nmissing</th><th style = \"text-align: left;\">eltype</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Symbol\" style = \"text-align: left;\">Symbol</th><th title = \"Union{Nothing, Float64}\" style = \"text-align: left;\">Union…</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Union{Nothing, Float64}\" style = \"text-align: left;\">Union…</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"DataType\" style = \"text-align: left;\">DataType</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">Year</td><td style = \"text-align: left;\">2003.02</td><td style = \"text-align: left;\">2001.0</td><td style = \"text-align: left;\">2003.0</td><td style = \"text-align: left;\">2005.0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">Lag1</td><td style = \"text-align: left;\">0.0038344</td><td style = \"text-align: left;\">-4.922</td><td style = \"text-align: left;\">0.039</td><td style = \"text-align: left;\">5.733</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">Lag2</td><td style = \"text-align: left;\">0.0039192</td><td style = \"text-align: left;\">-4.922</td><td style = \"text-align: left;\">0.039</td><td style = \"text-align: left;\">5.733</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">Lag3</td><td style = \"text-align: left;\">0.001716</td><td style = \"text-align: left;\">-4.922</td><td style = \"text-align: left;\">0.0385</td><td style = \"text-align: left;\">5.733</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">Lag4</td><td style = \"text-align: left;\">0.001636</td><td style = \"text-align: left;\">-4.922</td><td style = \"text-align: left;\">0.0385</td><td style = \"text-align: left;\">5.733</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">Lag5</td><td style = \"text-align: left;\">0.0056096</td><td style = \"text-align: left;\">-4.922</td><td style = \"text-align: left;\">0.0385</td><td style = \"text-align: left;\">5.733</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">Volume</td><td style = \"text-align: left;\">1.4783</td><td style = \"text-align: left;\">0.35607</td><td style = \"text-align: left;\">1.42295</td><td style = \"text-align: left;\">3.15247</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">Today</td><td style = \"text-align: left;\">0.0031384</td><td style = \"text-align: left;\">-4.922</td><td style = \"text-align: left;\">0.0385</td><td style = \"text-align: left;\">5.733</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">Direction</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">Down</td><td style = \"font-style: italic; text-align: left;\"></td><td style = \"text-align: left;\">Up</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">CategoricalValue{String, UInt8}</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & Year & 2003.02 & 2001.0 & 2003.0 & 2005.0 & 0 & Float64 \\\\\n",
       "\t2 & Lag1 & 0.0038344 & -4.922 & 0.039 & 5.733 & 0 & Float64 \\\\\n",
       "\t3 & Lag2 & 0.0039192 & -4.922 & 0.039 & 5.733 & 0 & Float64 \\\\\n",
       "\t4 & Lag3 & 0.001716 & -4.922 & 0.0385 & 5.733 & 0 & Float64 \\\\\n",
       "\t5 & Lag4 & 0.001636 & -4.922 & 0.0385 & 5.733 & 0 & Float64 \\\\\n",
       "\t6 & Lag5 & 0.0056096 & -4.922 & 0.0385 & 5.733 & 0 & Float64 \\\\\n",
       "\t7 & Volume & 1.4783 & 0.35607 & 1.42295 & 3.15247 & 0 & Float64 \\\\\n",
       "\t8 & Today & 0.0031384 & -4.922 & 0.0385 & 5.733 & 0 & Float64 \\\\\n",
       "\t9 & Direction &  & Down &  & Up & 0 & CategoricalValue\\{String, UInt8\\} \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m9×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable  \u001b[0m\u001b[1m mean      \u001b[0m\u001b[1m min     \u001b[0m\u001b[1m median  \u001b[0m\u001b[1m max     \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype      \u001b[0m ⋯\n",
       "     │\u001b[90m Symbol    \u001b[0m\u001b[90m Union…    \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Union…  \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m DataType    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ Year       2003.02    2001.0   2003.0   2005.0          0  Float64      ⋯\n",
       "   2 │ Lag1       0.0038344  -4.922   0.039    5.733           0  Float64\n",
       "   3 │ Lag2       0.0039192  -4.922   0.039    5.733           0  Float64\n",
       "   4 │ Lag3       0.001716   -4.922   0.0385   5.733           0  Float64\n",
       "   5 │ Lag4       0.001636   -4.922   0.0385   5.733           0  Float64      ⋯\n",
       "   6 │ Lag5       0.0056096  -4.922   0.0385   5.733           0  Float64\n",
       "   7 │ Volume     1.4783     0.35607  1.42295  3.15247         0  Float64\n",
       "   8 │ Today      0.0031384  -4.922   0.0385   5.733           0  Float64\n",
       "   9 │ Direction \u001b[90m           \u001b[0m Down    \u001b[90m         \u001b[0m Up              0  CategoricalV ⋯\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smarket = dataset(\"ISLR\", \"Smarket\")\n",
    "rows, cols = dataShape(smarket)\n",
    "println(\"El DataFrame consta de $(cols) columnas y $(rows) registros\")\n",
    "describe(smarket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b53af21-b5f9-43eb-b4dc-07493176ba4e",
   "metadata": {},
   "source": [
    "Este _data set_ contiene el valor de los rendimientos porcentuales del índice bursátil S&P 500 durante 1250 días, desde principios de 2001 hasta finales de 2005. Para cada día, se tiene registrado los rendimientos porcentuales de cada uno de los cinco días de negociación anteriores, etiquetados como **Lag1**, ..., **Lag5**. También se tiene registrado **Volume** (que es la cantidad de acciones negociadas el día anterior, en miles de millones), **Today** (el rendimiento porcentual en la fecha en cuestión) y **Direction** (si el mercado estaba en alza o en baja en esta fecha). Esta ultima es nuestra **variable dependiente**, es decir, será la variable que necesitamos predecir usando los diversos métodos de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673241e8-f26e-4707-a8c0-8331a7f7bdd3",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e4eaa-aad3-483a-bc4c-e2db9c7c1f36",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11f4eb3-b50f-4e54-9096-5878fced5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna Year tiene 0.0 % de datos faltantes\n",
      "La columna Lag1 tiene 0.0 % de datos faltantes\n",
      "La columna Lag2 tiene 0.0 % de datos faltantes\n",
      "La columna Lag3 tiene 0.0 % de datos faltantes\n",
      "La columna Lag4 tiene 0.0 % de datos faltantes\n",
      "La columna Lag5 tiene 0.0 % de datos faltantes\n",
      "La columna Volume tiene 0.0 % de datos faltantes\n",
      "La columna Today tiene 0.0 % de datos faltantes\n",
      "La columna Direction tiene 0.0 % de datos faltantes\n"
     ]
    }
   ],
   "source": [
    "for col in names(smarket)\n",
    "    println(\"La columna $(col) tiene $(dataMissingPercentage(smarket[!,col])) % de datos faltantes\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d55ad93-8cc6-48f0-b62c-e75e7d76b667",
   "metadata": {},
   "source": [
    "En el _data set_ no hay ningún dato faltante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e9eb2-fd60-4656-827d-24228c950fe4",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088fbc6-0c9c-4118-9862-78fcef7bb0c0",
   "metadata": {},
   "source": [
    "La variable **Direction** tiene dos posibles valores categoricos: _Up_ y _Down_. Estos valores necesitan ser transformados a valores númericos 0 y 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8a2c088-5f6b-4f18-b8ba-85494b022f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y será el array que contenga la codificación de la variable Direction\n",
    "y = map( x -> if x == \"Down\" 0 elseif x == \"Up\" 1 end, smarket.Direction);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d880cc21-f494-4270-8c0a-7ee170b6c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X serán los datos númericos\n",
    "X = select(smarket, Not(:Direction));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee88bd-8409-4746-a134-0fe6e6c5ab42",
   "metadata": {},
   "source": [
    "### Datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad659e-6d9a-4a1f-9dd2-92cf325e58cd",
   "metadata": {},
   "source": [
    "Lo siguiente es dividir nuestro conjunto de datos en dos subconjuntos: el de entrenamiento (70%) y el de prueba (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a0cb3c6-bb89-404a-a42d-41f5ac696ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(18)\n",
    "\n",
    "# rows es el número total de registros\n",
    "# Muestra aleatoria de indices para los datos de entrenamiento (70% de los datos)\n",
    "idx_train = sample(1:rows, Int(round(0.7*rows)), replace = false)\n",
    "# Indices restantes para los datos de prueba\n",
    "idx_test = Not(idx_train)\n",
    "#Datos entrenamiento\n",
    "train_X = Matrix(X[idx_train,:])\n",
    "train_y = y[idx_train]\n",
    "#Datos prueba\n",
    "test_X = Matrix(X[idx_test,:])\n",
    "test_y = y[idx_test];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37261df-a769-453e-9c65-554ac25e8388",
   "metadata": {},
   "source": [
    "## Algoritmos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b7cb22-80e7-4345-b6a8-acf7b533857b",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37211ad-08ea-42c1-9b32-60e2167c3a08",
   "metadata": {},
   "source": [
    "La regresión lineal (que es el método más sencillo entre los modelos lineales) estima la variable objetivo mediante una combinación lineal de las características predictivas, minimizando la _suma de los cuadrados de los residuales_ (RSS) \n",
    "$$RSS = \\sum_{i=1}^n (y_i - f(x_i))^2 $$ donde $n$ es el número de muestras, $y_i$ es el valor real observado y $f(x_i)$ el valor predicho. \n",
    "\n",
    "La **Regresión Rigde** regulariza el modelo resultante imponiendo una penalización al tamaño de los coeficientes de la relación lineal entre las características predictivas y la variable objetivo, con el objetivo de corregir la multicolinealidad en el análisis de regresión. En este caso, los coeficientes calculados minimizan la suma de los cuadrados de los residuos penalizada al añadir el cuadrado de la norma L2 del vector formado por los coeficientes:\n",
    "$$RSS = \\sum_{i=1}^n (y_i - f(x_i))^2 + \\lambda \\sum_{j=1}^p \\beta_j^2 $$ donde $\\beta_j$ son los coeficientes de la relación lineal y $\\lambda$ es el parámetro que controla el grado de penalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b40a59-1901-4ebd-b155-fa4bbd67f894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Cross Validation\n",
       "100 models for 8 predictors in 10 folds\n",
       "Best λ 0.036 (mean loss 0.119, std 0.002)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ridge_models es el conjunto de modelos generados para diferentes valores de λ\n",
    "# pero sólo nos interesa el modelo que tenga el mejor valor de λ (menor RSS promedio, MSE); para ello se usa la validación cruzada:\n",
    "ridge_models = glmnet(train_X, train_y, alpha = 0)#, standardize=true)\n",
    "cv_rm = glmnetcv(train_X, train_y, alpha = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e90c033-24e4-4ff4-ab74-e0ea3b76959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Solution Path (1 solutions for 8 predictors in 7 passes):\n",
       "────────────────────────────\n",
       "     df   pct_dev          λ\n",
       "────────────────────────────\n",
       "[1]   8  0.533414  0.0363067\n",
       "────────────────────────────"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda y modelo elegido\n",
    "λ = ridge_models.lambda[argmin(cv_rm.meanloss)]\n",
    "ridge_model = glmnet(train_X, train_y, alpha = 0, lambda = [λ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0bff1-b2d1-4c03-ac8c-e54a57e33b88",
   "metadata": {},
   "source": [
    "De un conjunto de 100 modelos, el mejor es aquel que tiene como parámetro $\\lambda = 0.0363067$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc1cd02a-78a6-4879-a3c3-d22d29eda35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones usando el set de prueba\n",
    "predictions_ridge = GLMNet.predict(ridge_model, test_X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "080691e8-341e-4a62-9759-0f00c5d3ce60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assign_class (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como se trata de un algoritmo de regresión, los valores predichos son continuos; \n",
    "# y dado que nuestro problema es categorico es necesario asignarle a cada valor su respectiva clase\n",
    "# assign_class es una función que obtiene la diferencia entre el valor predicho y el valor real, de manera que se elige el que tenga menor diferencia\n",
    "assign_class(predictedvalue) = [0,1][argmin(abs.(predictedvalue .- [0,1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a5f8738-cab4-46b2-bd12-8190c3c4421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          ┌─────────────┐\n",
       "          │Ground Truth │\n",
       "┌─────────┼──────┬──────┤\n",
       "│Predicted│  0   │  1   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    0    │ 162  │  4   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    1    │  11  │ 198  │\n",
       "└─────────┴──────┴──────┘\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones ya clasificadas\n",
    "yhat = vec(assign_class.(predictions_ridge))\n",
    "# Precisión\n",
    "acc_ridge = accuracy(yhat, test_y)\n",
    "println(\"Precisión: $acc_ridge\")\n",
    "confusion_matrix(yhat, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f094faf-3b6d-4e1e-a42c-fb8d9c3e0d0b",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ec737-b238-41d8-a1c5-e703112b6d5a",
   "metadata": {},
   "source": [
    "Lasso (_Least Absolute Shrinkage and Selection Operator_) es un modelo lineal que penaliza el vector de coeficientes añadiendo su norma L1 (basada en la distancia Manhattan) a la función de coste:\n",
    "$$ RSS = \\sum_{i=1}^n (y_i - f(x_i))^2 + \\lambda \\sum_{j=1}^p |\\beta_j|  $$\n",
    "La regularización L1 funciona reduciendo los coeficientes a cero, eliminando esencialmente esas variables independientes del modelo. Tanto la regresión Lasso como la regresión Ridge reducen la complejidad del modelo, aunque por medios diferentes. La regresión Lasso reduce el número de variables independientes que afectan a la salida. La regresión Ridge reduce el peso que cada variable independiente tiene en la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e257700d-1187-41f8-8cd6-53fd3f1a8c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Cross Validation\n",
       "67 models for 8 predictors in 10 folds\n",
       "Best λ 0.007 (mean loss 0.119, std 0.003)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_models = glmnet(train_X, train_y)\n",
    "cv_lm = glmnetcv(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb6de56a-df0e-434f-9394-2b24fbf642a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Solution Path (1 solutions for 8 predictors in 8 passes):\n",
       "─────────────────────────────\n",
       "     df   pct_dev           λ\n",
       "─────────────────────────────\n",
       "[1]   6  0.534248  0.00729486\n",
       "─────────────────────────────"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda y modelo elegido\n",
    "λ = lasso_models.lambda[argmin(cv_lm.meanloss)]\n",
    "lasso_model = glmnet(train_X, train_y, lambda = [λ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe04f3-0b25-4aac-a806-43d192f8475a",
   "metadata": {},
   "source": [
    "De un conjunto de 67 modelos, el mejor es aquel que tiene como parámetro $\\lambda = 0.0080061$, pero a diferencia de Ridge, este modelo **sólo tiene 6 variables predictoras**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ac34414-900c-4cf5-b29f-9e2633298454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          ┌─────────────┐\n",
       "          │Ground Truth │\n",
       "┌─────────┼──────┬──────┤\n",
       "│Predicted│  0   │  1   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    0    │ 165  │  1   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    1    │  8   │ 201  │\n",
       "└─────────┴──────┴──────┘\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones usando el set de prueba\n",
    "predictions_lasso = GLMNet.predict(lasso_model, test_X)\n",
    "# Predicciones ya clasificadas\n",
    "yhat = vec(assign_class.(predictions_lasso))\n",
    "\n",
    "acc_lasso = accuracy(yhat, test_y)\n",
    "println(\"Precisión: $acc_lasso\")\n",
    "# Matriz de confusión\n",
    "confusion_matrix(yhat, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7229f93-2d63-4a41-95f8-7bd7d0028be1",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1848011b-a9c8-48aa-bc2a-1f65b84251fb",
   "metadata": {},
   "source": [
    "Elastic Net es un modelo de regresión lineal que normaliza el vector de coeficientes con las normas L1 y L2. Mientras que la regresión Ridge obtiene su parámetro de regularización a partir de la suma de errores al cuadrado y Lasso obtiene el suyo a partir de la suma del valor absoluto de los errores, Elastic Net incorpora ambos parámetros de regularización en la función de coste RSS.\n",
    "$$ RSS = \\sum_{i=1}^n (y_i - f(x_i))^2 + \\alpha \\left(\\lambda \\sum_{j=1}^p \\beta_j^2 + (1-\\lambda) \\sum_{j=1}^p |\\beta_j| \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bfbac8a-555d-4dc9-b459-0ae2751fc9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Cross Validation\n",
       "67 models for 8 predictors in 10 folds\n",
       "Best λ 0.008 (mean loss 0.119, std 0.004)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EN_models = glmnet(train_X, train_y)\n",
    "cv_ENm = glmnetcv(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33916ac6-a544-4586-91ae-36fe62e6640a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Solution Path (1 solutions for 8 predictors in 8 passes):\n",
       "────────────────────────────\n",
       "     df   pct_dev          λ\n",
       "────────────────────────────\n",
       "[1]   6  0.533975  0.0080061\n",
       "────────────────────────────"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda y modelo elegido\n",
    "λ = EN_models.lambda[argmin(cv_ENm.meanloss)]\n",
    "EN_model = glmnet(train_X, train_y, lambda = [λ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dedc9a5-cad7-49b1-a4b9-d6a62f8f5833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.9733333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          ┌─────────────┐\n",
       "          │Ground Truth │\n",
       "┌─────────┼──────┬──────┤\n",
       "│Predicted│  0   │  1   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    0    │ 164  │  1   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    1    │  9   │ 201  │\n",
       "└─────────┴──────┴──────┘\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones usando el set de prueba\n",
    "predictions_EN = GLMNet.predict(EN_model, test_X)\n",
    "# Predicciones ya clasificadas\n",
    "yhat = vec(assign_class.(predictions_EN))\n",
    "\n",
    "acc_EN = accuracy(yhat, test_y)\n",
    "println(\"Precisión: $acc_EN\")\n",
    "# Matriz de confusión\n",
    "confusion_matrix(yhat, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feb2011-9dc7-47eb-87a0-db34722c35f7",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504192de-577d-40fc-b91b-b443310ed278",
   "metadata": {},
   "source": [
    "Un árbol de decisión, tal y como su nombre sugiere, crea, a partir de los datos de entrenamiento, una estructura en forma de árbol en la que, en cada nodo, va dividiendo los datos de forma que los bloques resultantes de cada división sean más \"puros\" que el bloque original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43709e5f-3462-4c4d-b0cf-0087f2b0d3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier\n",
       "max_depth:                3\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "classes:                  [0, 1]\n",
       "root:                     Decision Tree\n",
       "Leaves: 2\n",
       "Depth:  1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de modelo y entrenamiento\n",
    "DT_model = DecisionTreeClassifier(max_depth=3)\n",
    "DecisionTree.fit!(DT_model, train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516d1d3-2c61-456f-8a2e-638caeb79266",
   "metadata": {},
   "source": [
    "El arbol generado es el más sencillo; solo se realiza la división directamente a los dos casos posibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ae24a4b-0f96-4e94-898d-9bdee3401d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 8 < -0.0005 ?\n",
      "├─ 0 : 429/429\n",
      "└─ 1 : 446/446\n",
      "Precisión: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          ┌─────────────┐\n",
       "          │Ground Truth │\n",
       "┌─────────┼──────┬──────┤\n",
       "│Predicted│  0   │  1   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    0    │ 173  │  0   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    1    │  0   │ 202  │\n",
       "└─────────┴──────┴──────┘\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar el árbol\n",
    "print_tree(DT_model)\n",
    "\n",
    "# Predecir con el modelo entrenado\n",
    "yhat = DecisionTree.predict(DT_model, test_X)\n",
    "\n",
    "acc_DT = accuracy(yhat, test_y)\n",
    "println(\"Precisión: $acc_DT\")\n",
    "# Matriz de confusión\n",
    "confusion_matrix(yhat, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c3c0d2-03c3-4f5a-8891-417df53caff2",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd03667-d9ab-4ae4-b3fb-8796a080e33c",
   "metadata": {},
   "source": [
    "A partir de un conjunto de entrenamiento, este algoritmo genera un cierto número de árboles de decisión, siendo entrenado cada uno de ellos con un subconjunto aleatorio de muestras extraídas con reemplazo. Además, durante la división de cada nodo, en lugar de considerar todas las características predictivas para encontrar el mejor criterio de división, solo considera un subconjunto de ellas. Como consecuencia de la aleatoriedad introducida, el sesgo o error del modelo aumenta ligeramente pero, gracias a la combinación de los modelos, decrece la varianza compensando el efecto negativo mencionado, dando como resultado un mejor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8b875c6-9ac5-4872-9280-b99089bec389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier\n",
       "n_trees:             5\n",
       "n_subfeatures:       -1\n",
       "partial_sampling:    0.7\n",
       "max_depth:           -1\n",
       "min_samples_leaf:    1\n",
       "min_samples_split:   2\n",
       "min_purity_increase: 0.0\n",
       "classes:             [0, 1]\n",
       "ensemble:            Ensemble of Decision Trees\n",
       "Trees:      5\n",
       "Avg Leaves: 8.0\n",
       "Avg Depth:  3.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model = RandomForestClassifier(n_trees = 5)\n",
    "DecisionTree.fit!(RF_model, train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb7c6b84-50c6-46d0-9cef-c0a7e47c0f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          ┌─────────────┐\n",
       "          │Ground Truth │\n",
       "┌─────────┼──────┬──────┤\n",
       "│Predicted│  0   │  1   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    0    │ 173  │  0   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    1    │  0   │ 202  │\n",
       "└─────────┴──────┴──────┘\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecir con el modelo entrenado\n",
    "yhat = DecisionTree.predict(RF_model, test_X)\n",
    "\n",
    "acc_RF = accuracy(yhat, test_y)\n",
    "println(\"Precisión: $acc_RF\")\n",
    "# Matriz de confusión\n",
    "confusion_matrix(yhat, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93aae4-bfe7-4186-9f80-507f7cc17a7b",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b95a3-296e-4582-b881-592d9a493989",
   "metadata": {},
   "source": [
    "El algoritmo **k-Nearest Neighbors** es un algoritmo de Machine Learning extremadamente simple: en clasificación, asigna una etiqueta de clase a un punto de datos basándose en las etiquetas de clase de los _k_ vecinos más cercanos en el conjunto de entrenamiento. Los vecinos se seleccionan según la distancia euclidiana u otra medida de distancia, y el número _k_ se especifica previamente. Este algoritmo se basa en la suposición de que los datos con etiquetas semejantes se encuentran cerca unos de otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45002baf-4066-4712-a820-25ef855ec154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KDTree{StaticArraysCore.SVector{8, Float64}, Euclidean, Float64, StaticArraysCore.SVector{8, Float64}}\n",
       "  Number of points: 875\n",
       "  Dimensions: 8\n",
       "  Metric: Euclidean(0.0)\n",
       "  Reordered: true"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indice k-d tree\n",
    "kdtree = KDTree(train_X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "662edc08-fb8f-4d19-a287-d1097a30b192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          ┌─────────────┐\n",
       "          │Ground Truth │\n",
       "┌─────────┼──────┬──────┤\n",
       "│Predicted│  0   │  1   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    0    │ 150  │  22  │\n",
       "├─────────┼──────┼──────┤\n",
       "│    1    │  23  │ 180  │\n",
       "└─────────┴──────┴──────┘\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrar los k = 5 vecinos más cercanos\n",
    "# Para cada punto de test_X se obtienen los k vecinos cercanos (sus indices en el array train_X) y su respectiva distancia\n",
    "indices, distancias = knn(kdtree, test_X', 10, true)\n",
    "\n",
    "# Predicción\n",
    "# Sólo nos interesan los indices de los vecinos; \n",
    "# para determinar la clase de un punto de test_X, se determina a que clase mayormente pertenecen los k vecinos\n",
    "# la función mode devuelve el número más frecuente de un conjunto\n",
    "yhat = [mode(train_y[idx]) for idx in indices]\n",
    "\n",
    "acc_kNN = accuracy(yhat, test_y)\n",
    "println(\"Precisión: $acc_kNN\")\n",
    "# Matriz de confusión\n",
    "confusion_matrix(yhat, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828997fc-e863-4bc6-9612-0701ced2b8b2",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8500265-9659-496b-a442-32d99bef80cd",
   "metadata": {},
   "source": [
    "Una _máquina de vector de soporte_ (SVM) es un algoritmo que clasifica los datos al encontrar una línea o hiperplano óptimo que maximice la distancia entre cada clase en un espacio N-dimensional. Se denomina _margen_ a la suma de las dos distancias que separan al hiperplano del punto más próximo de cada clase. Luego, la posición del hiperplano de máximo margen y, por lo tanto, el propio margen dependen de los puntos de cada clase más próximos a la frontera de decisión, puntos que se conocen como _Support Vectors_ o _Vectores de Soporte_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5224988a-c8b3-4718-b351-4d17744f9f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          ┌─────────────┐\n",
       "          │Ground Truth │\n",
       "┌─────────┼──────┬──────┤\n",
       "│Predicted│  0   │  1   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    0    │ 168  │  7   │\n",
       "├─────────┼──────┼──────┤\n",
       "│    1    │  5   │ 195  │\n",
       "└─────────┴──────┴──────┘\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_model = svmtrain(train_X', train_y)\n",
    "yhat, = svmpredict(SVM_model, test_X')\n",
    "\n",
    "acc_SVM = accuracy(yhat, test_y)\n",
    "println(\"Precisión: $acc_SVM\")\n",
    "# Matriz de confusión\n",
    "confusion_matrix(yhat, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46375bf6-4b0f-430e-bf33-3ef3e41f1762",
   "metadata": {},
   "source": [
    "## Resumén de precisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef70eec9-c6a8-45b1-8367-3af75a3b318b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7×2 Matrix{Any}:\n",
       " \"Ridge\"          0.96\n",
       " \"LASSO\"          0.976\n",
       " \"Elastic Net\"    0.973333\n",
       " \"Decision Tree\"  1.0\n",
       " \"Random Forest\"  1.0\n",
       " \"kNN\"            0.88\n",
       " \"SVM\"            0.968"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method = [\"Ridge\", \"LASSO\", \"Elastic Net\", \"Decision Tree\", \"Random Forest\", \"kNN\", \"SVM\"]\n",
    "accuracies = [acc_ridge, acc_lasso, acc_EN, acc_DT, acc_RF, acc_kNN, acc_SVM]\n",
    "hcat(method, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4affed-db73-4589-bbc0-0aec177b6439",
   "metadata": {},
   "source": [
    "El mejor método de clasificación es **Decision Tree**, al tener una precisión del 100%. Si bien, Random Forest también logra clasificar perfectamente,  Decision Tree es un algoritmo más simple. Por otro lado, kNN es el metodo con menor precisión."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
